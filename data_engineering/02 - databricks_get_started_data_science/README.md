# Course Name: Get Started with Databricks Machine Learning Databricks Academy
<Add year here)


## Description

## Table of Contents
- [Course Overview](#course-overview)
- [Authors](#authors)
- [Additional Info about Implementation](#implementation)

## Course Overview

1. Learn how to load a dataframe from csv, wrap it with pyspark.pandas.DataFrame, save its features schema and feature values in a feature store using FeatureStoreClient. 
2. Create a baseline model using AutoML, register and stage it
3. Run batch inference on the baseline model using saved features in feature store
4. Learn how to create a job in databricks workflows to retrain the model monthly

## Authors
- Romain Futrzynski - Customer Success Engineer @ Databricks

## Implementation

Concepts learned:

- Describe the core components that make up the Databricks Lakehouse Platform.
- Describe functionality behind key components of Databricks ML (Feature Store, AutoML, MLflow). 
- Navigate the Databricks ML user-interface. 
- Use pyspark pandas wrapper
- Create a feature table using Feature Store in Databricks ML. 
- Develop a baseline model using AutoML (UI and code) in Databricks ML.
- Manage the machine learning model lifecycle using Model Registry in Databricks ML. 
- Use a registered model and feature table to perform batch inference in Databricks ML.
- Schedule a model refresh using Databricks Workflows and AutoML in Databricks ML.

